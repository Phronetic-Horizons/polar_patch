import logging
import importlib
import importlib.util
import importlib.metadata
from typing import TYPE_CHECKING, Any, Generator
from pathlib import Path
from dataclasses import dataclass

import polars as pl
import aiofiles

if TYPE_CHECKING:
  from polar_patch.ast.collector import PolarsPluginCollector
  from polar_patch.models.plugin import PluginInfoDC

logger = logging.getLogger(__name__)

PP_TOML_FILENAME = "polar_patch.toml"
PP_LOCK_FILENAME = "polar_patch.lock"


@dataclass
class PolarsDependencyResolver:
  def __init__(self) -> None:
    self.dependencies = pl.DataFrame(
      {
        "modname": pl.Series(dtype=pl.Utf8),
        "cls_name": pl.Series(dtype=pl.Utf8),
        "namespace": pl.Series(dtype=pl.Utf8),
        "polars_namespace": pl.Series(dtype=pl.Utf8),
        "version": pl.Series(dtype=pl.Utf8),
        "source": pl.Series(dtype=pl.Utf8),
      }
    )
    self.conflicts = pl.DataFrame(
      {
        "namespace": pl.Series(dtype=pl.Utf8),
        "conflict": pl.Series(dtype=pl.Utf8),
      }
    )

  def yield_dependency_paths(self) -> Generator[Path, Any, None]:
    lock_file_path = Path(PP_LOCK_FILENAME)
    if not lock_file_path.exists():
      logger.error(f"Lock file {PP_LOCK_FILENAME} does not exist. Please run the resolver first.")
      return

    with open(lock_file_path, "r") as lock_file:
      for line in lock_file:
        if line.startswith("-e") or line.startswith("#"):
          continue
        yield Path(line.strip().split("==")[0])

  async def create_lock_file(self, lock_file_path: Path) -> None:
    lock_content = ["# generated by PolarsDependencyResolver", "# use `pp lock` to update this lockfile", ""]
    for row in self.dependencies.iter_rows(named=True):
      lock_content.append(f"{row['modname']}=={row['version']}")
      if row["source"]:
        lock_content.append(f"    # via {row['source']}")
    async with aiofiles.open(lock_file_path, "w") as lock_file:
      await lock_file.write("\n".join(lock_content))
    logger.info(f"Lock file created at {lock_file_path}")

  def resolve_versions_and_detect_conflicts(self) -> pl.DataFrame | None:
    grouped = self.dependencies.group_by("namespace").agg(unique_versions=pl.col("version").n_unique(), versions=pl.col("version"))
    conflicts = grouped.filter(pl.col("unique_versions") > 1)
    if conflicts.is_empty():
      return None
    self.conflicts = conflicts.select(
      namespace=pl.col("namespace"),
      conflict=pl.col("versions").map_batches(lambda versions: f"Conflict: {', '.join(versions)}"),
    )
    for row in self.conflicts.iter_rows(named=True):
      logger.warning(f"Conflict detected in namespace '{row['namespace']}': {row['conflict']}")
    return self.conflicts

  async def collect_dependencies(self, dependency_collector: "PolarsPluginCollector") -> None:
    await dependency_collector.collect()
    self.dependencies = pl.DataFrame(
      {
        "modname": [plugin.modname for plugin in dependency_collector.plugins],
        "cls_name": [plugin.cls_name for plugin in dependency_collector.plugins],
        "namespace": [plugin.namespace for plugin in dependency_collector.plugins],
        "polars_namespace": [plugin.polars_namespace for plugin in dependency_collector.plugins],
        "version": [self.get_plugin_version(plugin) for plugin in dependency_collector.plugins],  # Fetch the version
        "source": ["polar-patch" for _ in dependency_collector.plugins],  # Example source
      }
    )

  def get_plugin_version(self, plugin: "PluginInfoDC") -> str:
    try:
      dist = importlib.metadata.distribution(plugin.modname)
    except importlib.metadata.PackageNotFoundError:
      logger.warning(f"Package {plugin.modname} not found, defaulting to 'unknown'")
      return "unknown"
    else:
      return dist.version

  async def resolve_dependencies(self) -> None:
    conflicts = self.resolve_versions_and_detect_conflicts()
    if conflicts is not None:
      logger.error("Conflicts detected, cannot proceed.")
    else:
      await self.create_lock_file(Path(PP_LOCK_FILENAME))
